---
title: "Budgeted Multi-Armed Bandits with Asymmetric Confidence Intervals"
authors: "Marco Heyden, Vadim Arzamasov, Edouard Fouché, Klemens Böhm"
collection: publications
permalink: /publication/2023-06-13-omega-ucb
excerpt: 'We present a UCB-sampling policy for the Budgeted MAB problem that uses asymmetric confidence intervals to overcome issues of existing policies; our policy achieves logarithmic regret and outperforms existing policies in synthetic and real settings.'
date: 2023-06-13
venue: 'arXiv preprint'
---
We study the stochastic Budgeted Multi-Armed Bandit (MAB) problem, where a player chooses from $K$ arms with unknown expected rewards and costs. The goal is to maximize the total reward under a budget constraint. A player thus seeks to choose the arm with the highest reward-cost ratio as often as possible. Current state-of-the-art policies for this problem have several issues, which we illustrate. To overcome them, we propose a new upper confidence bound (UCB) sampling policy, $\omega$-UCB, that uses asymmetric confidence intervals. These intervals scale with the distance between the sample mean and the bounds of a random variable, yielding a more accurate and tight estimation of the reward-cost ratio compared to our competitors. We show that our approach has logarithmic regret and consistently outperforms existing policies in synthetic and real settings.

[Access paper](https://arxiv.org/abs/2306.07071)
