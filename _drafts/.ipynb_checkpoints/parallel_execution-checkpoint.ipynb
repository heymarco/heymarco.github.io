{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating machine learning algorithms typically requires\n",
    "1. comparing ones own algorithm to the state of the art.\n",
    "2. repeating an experiment multiple times to obtain reliable results.\n",
    "\n",
    "One way to do this is to loop over all algorithms, data sets, and experiment repetitions or folds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T16:04:18.383035500Z",
     "start_time": "2023-07-10T16:04:15.415734500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Mushrooms</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.946667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.953333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Accuracy\n",
       "Dataset   Algorithm              \n",
       "Mushrooms Decision Tree  0.946667\n",
       "          Random Forest  0.953333"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "def load_dataset_with_id(id):\n",
    "    ds = fetch_openml(data_id=id, parser='auto')\n",
    "    data = ds.data\n",
    "    target = ds.target\n",
    "    return data, target\n",
    "\n",
    "iris_data, iris_targets = load_dataset_with_id(61)\n",
    "\n",
    "algs = {\"Decision Tree\": DecisionTreeClassifier(),\n",
    "        \"Random Forest\": RandomForestClassifier()}\n",
    "datasets = {\"Mushrooms\": (iris_data, iris_targets)}\n",
    "n_folds = 5\n",
    "\n",
    "result = []\n",
    "for alg_name, alg_blueprint in algs.items():\n",
    "    alg = copy.deepcopy(alg_blueprint)\n",
    "    for ds_name, (X, y) in datasets.items():\n",
    "        cv = KFold(n_splits=n_folds, shuffle=True, random_state=0)\n",
    "        for fold, (train_indices, test_indices) in enumerate(cv.split(X, y)):\n",
    "            X_train, y_train = X.iloc[train_indices], y.iloc[train_indices]\n",
    "            X_test, y_test = X.iloc[test_indices], y.iloc[test_indices]\n",
    "            alg.fit(X_train, y_train)\n",
    "            accuracy = alg.score(X_test, y_test)\n",
    "            result.append([alg_name, ds_name, fold, accuracy])\n",
    "\n",
    "df = pd.DataFrame(result, columns=[\"Algorithm\", \"Dataset\", \"Fold\", \"Accuracy\"])\n",
    "df.drop(\"Fold\", axis=1).groupby([\"Dataset\", \"Algorithm\"]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Needless to say, this is is incredibly slow! So let's get rid of the nested loops and use multiprocessing instead.\n",
    "\n",
    "Let's define a function that wraps the code in the inner loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T16:04:18.401047700Z",
     "start_time": "2023-07-10T16:04:18.383035500Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_alg(alg, X, y, train_indices, test_indices):\n",
    "    X_train, y_train = X.iloc[train_indices], y.iloc[train_indices]\n",
    "    X_test, y_test = X.iloc[test_indices], y.iloc[test_indices]\n",
    "    alg.fit(X_train, y_train)\n",
    "    accuracy = alg.score(X_test, y_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create two lists; this is where it gets interesting:\n",
    "1. `id_list`: a list of lists that allows us to map the results of our experiment to algorithm-dataset-fold combinations.\n",
    "2. `arguments_list`: a list of lists where each entry corresponds to a list of parameters that we can pass to `evaluate_alg`\n",
    "\n",
    "Later on, we will join `id_list` with the results to obtain the final dataframe.\n",
    "\n",
    "We create the lists with the code below. Essentially, we loop over all algorithms, datasets and folds and store their combination for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T16:04:18.525328100Z",
     "start_time": "2023-07-10T16:04:18.391901800Z"
    }
   },
   "outputs": [],
   "source": [
    "id_list = []\n",
    "arguments_list = []\n",
    "for alg_name, alg_blueprint in algs.items():\n",
    "    alg = copy.deepcopy(alg_blueprint)\n",
    "    for ds_name, (X, y) in datasets.items():\n",
    "        cv = KFold(n_splits=n_folds, shuffle=True, random_state=0)\n",
    "        for fold, (train_indices, test_indices) in enumerate(cv.split(X, y)):\n",
    "            id_list.append([\n",
    "                alg_name, ds_name, fold\n",
    "            ])\n",
    "            arguments_list.append([\n",
    "                alg, X, y, train_indices, test_indices\n",
    "            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us define a function to parallelize our experiment. `run_async` takes\n",
    "- a function (the one we want to run in parallel),\n",
    "- a list of lists of arguments for that function,\n",
    "- the number of jobs to use during parallization,\n",
    "- and a configurable sleep time that controls how frequently we check if our function executions are finished.\n",
    "\n",
    "Note that `run_async` returns the results in the same order as specified by the `args_list`. This allows mapping the results to the configurations stored in `id_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T16:04:18.628348Z",
     "start_time": "2023-07-10T16:04:18.417346800Z"
    }
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "def run_async(function, args_list, njobs, sleep_time_s = 0.1):\n",
    "    pool = Pool(njobs)\n",
    "    results = {i: pool.apply_async(function, args=args)\n",
    "               for i, args in enumerate(args_list)}\n",
    "    while not all(future.ready() for future in results.values()):\n",
    "        sleep(sleep_time_s)\n",
    "    results = [results[i].get() for i in range(len(results))]\n",
    "    pool.close()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let us run our experiment in parallel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T16:05:20.843721Z",
     "start_time": "2023-07-10T16:04:18.435658500Z"
    }
   },
   "outputs": [],
   "source": [
    "from multiprocessing import cpu_count\n",
    "\n",
    "njobs = cpu_count()\n",
    "results = run_async(evaluate_alg, arguments_list, njobs=njobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now join the `results` with the previously created `id_list`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = [\n",
    "    id_list_item.append(result) for id_list_item in zip(id_list, results)\n",
    "]\n",
    "final_df = pd.DataFrame(final_data, columns=[\"Algorithm\", \"Dataset\", \"Fold\", \"Accuracy\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
